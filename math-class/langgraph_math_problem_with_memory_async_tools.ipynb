{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict, Any, TypedDict, Annotated\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import ToolMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "from IPython.display import Image, SVG, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Return the sum of two integers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# Add these new tools to your existing TOOLS list\n",
    "@tool\n",
    "def subtract_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Return the difference of two integers (a - b).\"\"\"\n",
    "    return a - b\n",
    "\n",
    "@tool\n",
    "def multiply_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Return the product of two integers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def divide_numbers(a: int, b: int) -> float:\n",
    "    \"\"\"Return the division of two integers (a / b).\"\"\"\n",
    "    if b == 0:\n",
    "        return \"Cannot divide by zero\"\n",
    "    return a / b\n",
    "\n",
    "# Update your TOOLS list\n",
    "TOOLS = [add_numbers, subtract_numbers, multiply_numbers, divide_numbers]\n",
    "TOOL_MAP = {t.name: t for t in TOOLS}\n",
    "\n",
    "# Async tool execution functions\n",
    "async def execute_tool_async(tool_call: dict, tool_map: dict) -> dict:\n",
    "    \"\"\"Execute a single tool call asynchronously.\"\"\"\n",
    "    name, args, tc_id = tool_call[\"name\"], tool_call[\"args\"], tool_call[\"id\"]\n",
    "    \n",
    "    print(f\"üîß Starting async: {name}({args})\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if name not in tool_map:\n",
    "        result = f\"Error: Tool {name} not found\"\n",
    "        success = False\n",
    "    else:\n",
    "        try:\n",
    "            # Run the tool in a thread pool to avoid blocking\n",
    "            loop = asyncio.get_event_loop()\n",
    "            with ThreadPoolExecutor() as executor:\n",
    "                result = await loop.run_in_executor(\n",
    "                    executor, \n",
    "                    lambda: tool_map[name].invoke(args)\n",
    "                )\n",
    "            success = True\n",
    "        except Exception as e:\n",
    "            result = f\"Error executing {name}: {str(e)}\"\n",
    "            success = False\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    print(f\"‚úÖ Completed {name}: {result} ({execution_time:.2f}s)\")\n",
    "    \n",
    "    return {\n",
    "        \"tool_call_id\": tc_id,\n",
    "        \"name\": name,\n",
    "        \"args\": args,\n",
    "        \"result\": result,\n",
    "        \"success\": success,\n",
    "        \"execution_time\": execution_time\n",
    "    }\n",
    "\n",
    "async def execute_tools_concurrently(tool_calls: list, tool_map: dict) -> list:\n",
    "    \"\"\"Execute multiple tool calls concurrently.\"\"\"\n",
    "    tasks = [execute_tool_async(tc, tool_map) for tc in tool_calls]\n",
    "    return await asyncio.gather(*tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathProblemState(TypedDict):\n",
    "    \"\"\"Math problem solving state using TypedDict for proper LangGraph compatibility.\"\"\"\n",
    "    messages: Annotated[List[Any], add_messages]  # LangGraph handles message merging automatically\n",
    "    problem: Optional[str]  # Original word problem text\n",
    "    current_step: int  # Current step number in the solution\n",
    "    calculations: List[Dict[str, Any]]  # History of calculations performed\n",
    "    final_answer: Optional[str]  # Final calculated answer\n",
    "\n",
    "\n",
    "class SimpleResponse(BaseModel):\n",
    "    problem_answer: int\n",
    "    confidence: float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_message_sequence(messages: List[Any]) -> bool:\n",
    "    \"\"\"Validate that tool messages follow AI messages with tool calls.\"\"\"\n",
    "    for i, msg in enumerate(messages):\n",
    "        if isinstance(msg, ToolMessage):\n",
    "            # Tool message must follow an AI message with tool calls\n",
    "            if i == 0:\n",
    "                return False, f\"ToolMessage at index {i} cannot be the first message\"\n",
    "            \n",
    "            prev_msg = messages[i-1]\n",
    "            if not isinstance(prev_msg, AIMessage):\n",
    "                return False, f\"ToolMessage at index {i} must follow an AIMessage, got {type(prev_msg).__name__}\"\n",
    "            \n",
    "            if not hasattr(prev_msg, 'tool_calls') or not prev_msg.tool_calls:\n",
    "                return False, f\"ToolMessage at index {i} follows AIMessage without tool_calls\"\n",
    "                \n",
    "            # Check if the tool call ID matches\n",
    "            tool_call_ids = [tc['id'] for tc in prev_msg.tool_calls]\n",
    "            if hasattr(msg, 'tool_call_id') and msg.tool_call_id not in tool_call_ids:\n",
    "                return False, f\"ToolMessage tool_call_id {msg.tool_call_id} not found in previous AIMessage\"\n",
    "    \n",
    "    return True, \"Message sequence is valid\"\n",
    "\n",
    "\n",
    "def debug_messages(messages: List[Any], title: str = \"Messages\"):\n",
    "    \"\"\"Debug helper to print message sequence.\"\"\"\n",
    "    print(f\"\\nüîç {title}:\")\n",
    "    for i, msg in enumerate(messages):\n",
    "        msg_type = type(msg).__name__\n",
    "        content = getattr(msg, 'content', '')[:50] + ('...' if len(getattr(msg, 'content', '')) > 50 else '')\n",
    "        tool_calls = getattr(msg, 'tool_calls', None)\n",
    "        tool_call_id = getattr(msg, 'tool_call_id', None)\n",
    "        \n",
    "        print(f\"  {i}: {msg_type}\")\n",
    "        if content:\n",
    "            print(f\"     Content: {content}\")\n",
    "        if tool_calls:\n",
    "            print(f\"     Tool calls: {len(tool_calls)} calls\")\n",
    "        if tool_call_id:\n",
    "            print(f\"     Tool call ID: {tool_call_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt template for math problem solving\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful math tutor. When given a word problem:\n",
    "\n",
    "1. First, identify what information is given and what needs to be found\n",
    "2. Break down the problem into clear steps\n",
    "3. Use the available tools (add_numbers, subtract_numbers, multiply_numbers, divide_numbers) to perform calculations\n",
    "4. Show your work step by step\n",
    "5. Provide a clear final answer\n",
    "\n",
    "Always use tools for calculations rather than doing math in your head. This ensures accuracy and shows the work clearly.\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0).bind_tools(TOOLS)\n",
    "\n",
    "def call_llm_with_memory(state: MathProblemState) -> Dict[str, Any]:\n",
    "    \"\"\"Enhanced LLM call that considers problem-solving context.\"\"\"    \n",
    "    messages = list(state[\"messages\"])  # Convert to list for TypedDict\n",
    "    \n",
    "    # Add system message if it's the first interaction\n",
    "    if len(messages) == 1 and isinstance(messages[0], HumanMessage):\n",
    "        from langchain_core.messages import SystemMessage\n",
    "        messages.insert(0, SystemMessage(content=SYSTEM_PROMPT))\n",
    "    \n",
    "    ai = llm.invoke(messages)\n",
    "    return {\"messages\": [ai]}\n",
    "\n",
    "\n",
    "def responder(state: MathProblemState) -> Dict[str, Any]:\n",
    "    \"\"\"Responder function to provide final answer with structured output.\"\"\"\n",
    "    messages = list(state[\"messages\"])\n",
    "    \n",
    "    # Add context about calculations if any were performed\n",
    "    model_messages = messages[-1]\n",
    "\n",
    "    if isinstance(model_messages, AIMessage):\n",
    "        context_msg = f\"\\nProblem solution: {model_messages.content}\\n\\nPlease provide a clear final answer.\"\n",
    "    \n",
    "    # Use the existing LLM instance - even with tools bound, it won't use them unless needed\n",
    "    structured_llm = llm.with_structured_output(SimpleResponse)\n",
    "    result = structured_llm.invoke(context_msg)\n",
    "    \n",
    "    # Serialize using Pydantic's built-in method\n",
    "    return {\"messages\": [AIMessage(content=str(result))], \"final_answer\": str(result.problem_answer)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tools_with_memory(state: MathProblemState) -> Dict[str, Any]:\n",
    "    \"\"\"Execute tool calls and track calculations in memory.\"\"\"\n",
    "    if not state[\"messages\"]:\n",
    "        return {\"messages\": [], \"calculations\": state[\"calculations\"]}\n",
    "        \n",
    "    last = state[\"messages\"][-1]\n",
    "    \n",
    "    # Only process if the last message is an AIMessage with tool calls\n",
    "    if not isinstance(last, AIMessage) or not getattr(last, \"tool_calls\", []):\n",
    "        return {\"messages\": [], \"calculations\": state[\"calculations\"]}\n",
    "    \n",
    "    tool_msgs = []\n",
    "    new_calculations = list(state[\"calculations\"]) if state[\"calculations\"] else []\n",
    "    \n",
    "    for tc in last.tool_calls:\n",
    "        name, args, tc_id = tc[\"name\"], tc[\"args\"], tc[\"id\"]\n",
    "        \n",
    "        # Validate that the tool exists\n",
    "        if name not in TOOL_MAP:\n",
    "            result = f\"Error: Tool {name} not found\"\n",
    "        else:\n",
    "            try:\n",
    "                result = TOOL_MAP[name].invoke(args)\n",
    "                \n",
    "                # Track the calculation\n",
    "                calculation = {\n",
    "                    \"operation\": name,\n",
    "                    \"inputs\": args,\n",
    "                    \"result\": result,\n",
    "                    \"step\": len(new_calculations) + 1\n",
    "                }\n",
    "                new_calculations.append(calculation)\n",
    "            except Exception as e:\n",
    "                result = f\"Error executing {name}: {str(e)}\"\n",
    "        \n",
    "        tool_msgs.append(\n",
    "            ToolMessage(\n",
    "                content=f\"Result: {result}\",\n",
    "                name=name,\n",
    "                tool_call_id=tc_id,\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    return {\n",
    "        \"messages\": tool_msgs,\n",
    "        \"calculations\": new_calculations,\n",
    "        \"current_step\": state[\"current_step\"] + 1\n",
    "    }\n",
    "\n",
    "def call_tools_with_memory_async(state: MathProblemState) -> Dict[str, Any]:\n",
    "    \"\"\"Execute tool calls asynchronously and track calculations in memory.\"\"\"\n",
    "    if not state[\"messages\"]:\n",
    "        return {\"messages\": [], \"calculations\": state[\"calculations\"]}\n",
    "        \n",
    "    last = state[\"messages\"][-1]\n",
    "    \n",
    "    # Only process if the last message is an AIMessage with tool calls\n",
    "    if not isinstance(last, AIMessage) or not getattr(last, \"tool_calls\", []):\n",
    "        return {\"messages\": [], \"calculations\": state[\"calculations\"]}\n",
    "    \n",
    "    # Execute tools asynchronously\n",
    "    async_results = asyncio.run(execute_tools_concurrently(last.tool_calls, TOOL_MAP))\n",
    "    \n",
    "    tool_msgs = []\n",
    "    new_calculations = list(state[\"calculations\"]) if state[\"calculations\"] else []\n",
    "    \n",
    "    for result in async_results:\n",
    "        tool_msgs.append(\n",
    "            ToolMessage(\n",
    "                content=f\"Result: {result['result']}\",\n",
    "                name=result[\"name\"],\n",
    "                tool_call_id=result[\"tool_call_id\"],\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if result[\"success\"]:\n",
    "            calculation = {\n",
    "                \"operation\": result[\"name\"],\n",
    "                \"inputs\": result[\"args\"],\n",
    "                \"result\": result[\"result\"],\n",
    "                \"step\": len(new_calculations) + 1\n",
    "            }\n",
    "            new_calculations.append(calculation)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": tool_msgs,\n",
    "        \"calculations\": new_calculations,\n",
    "        \"current_step\": state[\"current_step\"] + 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def needs_tool(state: MathProblemState) -> str:\n",
    "    \"\"\"Determine if tools are needed or if we should provide final response.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    if not messages:\n",
    "        return END\n",
    "    \n",
    "    last = messages[-1]\n",
    "    has_calls = bool(getattr(last, \"tool_calls\", []) or [])\n",
    "    decision = \"tools\" if has_calls else \"responder\"\n",
    "    return decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_math_graph():\n",
    "    workflow = StateGraph(state_schema=MathProblemState)\n",
    "    \n",
    "    workflow.add_node(\"model\", call_llm_with_memory)\n",
    "    workflow.add_node(\"tools\", call_tools_with_memory_async)\n",
    "    workflow.add_node(\"responder\", responder)  # Fixed: use the actual responder function\n",
    "\n",
    "    workflow.set_entry_point(\"model\")\n",
    "    workflow.add_conditional_edges(\"model\", needs_tool, {\"tools\": \"tools\", \"responder\": \"responder\"})\n",
    "    workflow.add_edge(\"tools\", \"model\")\n",
    "    workflow.add_edge(\"responder\", END)\n",
    "\n",
    "    checkpointer = MemorySaver()\n",
    "    return workflow.compile(checkpointer=checkpointer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_tally = {\"p\": 0, \"c\": 0, \"t\": 0}\n",
    "seen_ids = set()  # to avoid reprinting old messages\n",
    "\n",
    "def log_step(chunk: dict):\n",
    "    # Handle both \"updates\" and \"values\" stream modes\n",
    "    if \"__end__\" in chunk:\n",
    "        return\n",
    "    \n",
    "    # If chunk has node names as keys (updates mode)\n",
    "    if any(key in [\"model\", \"tools\", \"__end__\"] for key in chunk.keys()):\n",
    "        for node, state in chunk.items():\n",
    "            if node == \"__end__\":\n",
    "                continue\n",
    "            _process_messages(node, state)\n",
    "    else:\n",
    "        # If chunk is the complete state (values mode)\n",
    "        _process_messages(\"STEP\", chunk)\n",
    "\n",
    "def _process_messages(node: str, state):\n",
    "    messages = state.get(\"messages\", []) if isinstance(state, dict) else []\n",
    "    msg = \"\"\n",
    "    if messages:\n",
    "        m = messages[-1]\n",
    "\n",
    "        if isinstance(m, HumanMessage):\n",
    "            msg = f\"[{node.upper()}] USER ‚Üí {m.content}\"\n",
    "        elif isinstance(m, AIMessage):\n",
    "            if getattr(m, \"tool_calls\", None):\n",
    "                for tc in m.tool_calls:\n",
    "                    msg += f\"[{node.upper()}] MODEL ‚Üí {tc['name']}(...)\\n\"\n",
    "            if m.content:\n",
    "                msg += f\"[{node.upper()}] MODEL ‚Üí {m.content}\"\n",
    "\n",
    "            usage = (m.response_metadata or {}).get(\"token_usage\", {})\n",
    "            p, c, t = usage.get(\"prompt_tokens\", 0), usage.get(\"completion_tokens\", 0), usage.get(\"total_tokens\", 0)\n",
    "            token_tally[\"p\"] += p\n",
    "            token_tally[\"c\"] += c\n",
    "            token_tally[\"t\"] += t\n",
    "            if t > 0:\n",
    "                msg += f\" ‚éØ tokens: {p}/{c}/{t}\"\n",
    "\n",
    "        elif isinstance(m, ToolMessage):\n",
    "            preview = m.content[:80] + (\"‚Ä¶\" if isinstance(m.content, str) and len(m.content) > 80 else \"\")\n",
    "            msg += f\"[{node.upper()}] TOOL ‚Üê {m.name}: {preview}\"\n",
    "\n",
    "    if msg:\n",
    "        print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STEP] USER ‚Üí Solve this step by step: \n",
      "John starts with $50. \n",
      "He buys 3 apples at $2 each and 2 oranges at $3 each.\n",
      "Then he finds $5 on the ground.\n",
      "How much money does John have left?\n",
      "\n",
      "[STEP] MODEL ‚Üí multiply_numbers(...)\n",
      "[STEP] MODEL ‚Üí multiply_numbers(...)\n",
      "[STEP] MODEL ‚Üí Let's break down the problem step by step.\n",
      "\n",
      "1. **Identify the information given:**\n",
      "   - John starts with $50.\n",
      "   - He buys 3 apples at $2 each.\n",
      "   - He buys 2 oranges at $3 each.\n",
      "   - He finds $5 on the ground.\n",
      "\n",
      "2. **What needs to be found:**\n",
      "   - The total amount of money John has left after his purchases and finding money.\n",
      "\n",
      "3. **Calculate the total cost of the apples:**\n",
      "   - Cost of 1 apple = $2\n",
      "   - Number of apples = 3\n",
      "   - Total cost of apples = 3 * 2\n",
      "\n",
      "4. **Calculate the total cost of the oranges:**\n",
      "   - Cost of 1 orange = $3\n",
      "   - Number of oranges = 2\n",
      "   - Total cost of oranges = 2 * 3\n",
      "\n",
      "5. **Calculate the total cost of fruits:**\n",
      "   - Total cost of fruits = Total cost of apples + Total cost of oranges\n",
      "\n",
      "6. **Calculate the remaining money after purchases:**\n",
      "   - Remaining money after purchases = Initial amount - Total cost of fruits\n",
      "\n",
      "7. **Add the money found:**\n",
      "   - Final amount = Remaining money after purchases + Money found\n",
      "\n",
      "Now, let's perform the calculations using the available tools. \n",
      "\n",
      "### Step 3: Calculate the total cost of the apples\n",
      "- Total cost of apples = 3 * 2\n",
      "\n",
      "### Step 4: Calculate the total cost of the oranges\n",
      "- Total cost of oranges = 2 * 3\n",
      "\n",
      "### Step 5: Calculate the total cost of fruits\n",
      "- Total cost of fruits = Total cost of apples + Total cost of oranges\n",
      "\n",
      "### Step 6: Calculate the remaining money after purchases\n",
      "- Remaining money after purchases = $50 - Total cost of fruits\n",
      "\n",
      "### Step 7: Add the money found\n",
      "- Final amount = Remaining money after purchases + $5\n",
      "\n",
      "Let's perform these calculations now. ‚éØ tokens: 281/450/731\n",
      "üîß Starting async: multiply_numbers({'a': 3, 'b': 2})\n",
      "üîß Starting async: multiply_numbers({'a': 2, 'b': 3})\n",
      "‚úÖ Completed multiply_numbers: 6 (0.00s)\n",
      "‚úÖ Completed multiply_numbers: 6 (0.00s)\n",
      "[STEP] TOOL ‚Üê multiply_numbers: Result: 6\n",
      "[STEP] MODEL ‚Üí subtract_numbers(...)\n",
      " ‚éØ tokens: 655/18/673\n",
      "üîß Starting async: subtract_numbers({'a': 50, 'b': 12})\n",
      "‚úÖ Completed subtract_numbers: 38 (0.00s)\n",
      "[STEP] TOOL ‚Üê subtract_numbers: Result: 38\n",
      "[STEP] MODEL ‚Üí add_numbers(...)\n",
      " ‚éØ tokens: 685/18/703\n",
      "üîß Starting async: add_numbers({'a': 38, 'b': 5})\n",
      "‚úÖ Completed add_numbers: 43 (0.00s)\n",
      "[STEP] TOOL ‚Üê add_numbers: Result: 43\n",
      "[STEP] MODEL ‚Üí Let's summarize the calculations step by step:\n",
      "\n",
      "1. **Total cost of apples:** \n",
      "   - 3 apples at $2 each = \\(3 \\times 2 = 6\\) dollars.\n",
      "\n",
      "2. **Total cost of oranges:** \n",
      "   - 2 oranges at $3 each = \\(2 \\times 3 = 6\\) dollars.\n",
      "\n",
      "3. **Total cost of fruits:** \n",
      "   - Total cost of apples + Total cost of oranges = \\(6 + 6 = 12\\) dollars.\n",
      "\n",
      "4. **Remaining money after purchases:** \n",
      "   - Initial amount - Total cost of fruits = \\(50 - 12 = 38\\) dollars.\n",
      "\n",
      "5. **Final amount after finding money:** \n",
      "   - Remaining money + Money found = \\(38 + 5 = 43\\) dollars.\n",
      "\n",
      "Therefore, John has **$43** left. ‚éØ tokens: 715/177/892\n",
      "[STEP] MODEL ‚Üí problem_answer=43 confidence=0.95\n"
     ]
    }
   ],
   "source": [
    "graph = get_math_graph()\n",
    "\n",
    "problem = \"\"\"\n",
    "John starts with $50. \n",
    "He buys 3 apples at $2 each and 2 oranges at $3 each.\n",
    "Then he finds $5 on the ground.\n",
    "How much money does John have left?\n",
    "\"\"\"\n",
    "\n",
    "# Reset token tally and seen IDs for fresh start\n",
    "token_tally = {\"p\": 0, \"c\": 0, \"t\": 0}\n",
    "seen_ids = set()\n",
    "\n",
    "# Create initial state using TypedDict (no more Pydantic!)\n",
    "initial_state: MathProblemState = {\n",
    "    \"messages\": [HumanMessage(content=f\"Solve this step by step: {problem}\")],\n",
    "    \"problem\": problem,\n",
    "    \"steps\": [],\n",
    "    \"current_step\": 0,\n",
    "    \"calculations\": [],\n",
    "    \"final_answer\": None\n",
    "}\n",
    "\n",
    "# No more model_dump() needed!\n",
    "config = {\"configurable\": {\"thread_id\": \"fresh_math_session\"}}\n",
    "\n",
    "# Pass the TypedDict directly to LangGraph\n",
    "for chunk in graph.stream(initial_state, config=config, stream_mode=\"values\"):\n",
    "    log_step(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'43'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk[\"final_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(graph.get_graph().draw_mermaid_png())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='problem_answer=43 confidence=0.95', additional_kwargs={}, response_metadata={}, id='24a6bc82-5854-41d0-b2af-585aa074b085')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk['messages'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zenvi-development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
